% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.
\chapter{Concept}\label{chapter:Concept}

The task of looking at a picture and telling what is in it, is quite trivial to humans and would usually not pose a challenging task to perform, whereas it is not that simple to Computers. In order to Classify images, or more exactly the objects comprised, machines ordinarily need a certain amount of Preprocessing to extract characteristic Features. As described in chapter \ref{chapter:Related Work} it is common practice to partition the many small steps of the process in two bigger, more generalized, steps of Feature Extraction and Classification. Our targeted devices are going to be any smartphones running Android as operating system, basically the App on the device should be able to handle live input from the Camera, detecting and classifying in real time. In the following subsections I am going to break down in detail, what  methods are used and how they work. \newline
Komponentendiagramm\newline


\begin{figure}[H]
	\minipage{0.33\textwidth}
	\includegraphics[width=\linewidth]{images/101.jpg}
	\caption{Original image}\label{fig:original_image}
	\endminipage\hfill
	\minipage{0.33\textwidth}
	\includegraphics[width=\linewidth]{images/filteredimg.png}
	\caption{Filtered Image}\label{fig:red_filtered_image}
	\endminipage\hfill
	\minipage{0.33\textwidth}%
	\includegraphics[width=\linewidth]{images/detectedimg.png}
	\caption{Detected image}\label{fig:detected_image}
	\endminipage
\end{figure}

\section{Feature Extraction}
Before we pass data through to the Classification phase, it is a reasonable step in our Program, to specify a Region Of Interest, with regard to saving some processing power. In order to specify ROIs, I took advantage of the red circle around European Speed signs, the main steps of this part are to filter every red pixel out of the original image (Figure: \ref{fig:red_filtered_image}), subsequently an algorithm checks the filtered image for circles (Figure: \ref{fig:detected_image}). Filtering red pixels from a picture is not that big of a sorcery, so i am going to skip that part for now and come back later to this in the implementation section. The real magic happens when you try to search an image for circles, therefore a common method is the Circle Hough Transform. 

\subsection{Circle Hough Transform}
The Circle Hough Transform is a special case of the Hough transform, which determines lines in an image through Edge Detection Algorithms. There are two slightly different Circle Hough Transforms, the first is only able to find circles of fixed radial size, the second is generally capable of finding Circles of any size. At first I am just going to start with the fixed radius form of the algorithm, subsequently we are going to extend that approach to a more universal algorithm.

\subsubsection{Fixed Radius}
First of all our image is being Converted to a binary image  (Figure: \ref{fig:binary_image}), further it is being processed via edge detection to determine every visible edge contained in the photo (Figure: \ref{fig:edge_detected_image}).
After this, the actual core of the Algorithm is being executed. Therefore an Accumulator Matrix is initialized with zeros. As the radius of the circle is considered constant, every ring in the picture can solely be described by two variables (x and y coordinate), therefore the helping Accumulator Matrix is 2-Dimensional.
Above-mentioned Matrix can be pictured as a grid over the original image, where single pixels can be combined to bigger baskets. Now every basket or pixel of a detected edge (Figure: \ref{fig:edge_detected_image}) becomes the center of a new circle, with given fixed radius. Now each pixel that got "cut" by the circle gets incremented or up-voted in corresponding Accumulator Matrix (Figure \ref{fig:voted_image}). The baskets or pixels with the highest votes can be considered centers of circles.
\newline

\begin{figure}[H]
	\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth]{images/circles.jpg}
	\caption{Binary image }\label{fig:binary_image}
	\endminipage\hfill
	\minipage{0.32\textwidth}
	\includegraphics[width=\linewidth]{images/circle_edges.jpg}
	\caption{Edge detected }\label{fig:edge_detected_image}
	\endminipage\hfill
	\minipage{0.32\textwidth}%
	\includegraphics[width=\linewidth]{images/hough_circle.jpg}
	\caption{Voted image }\label{fig:voted_image}
	\endminipage
\end{figure}

\subsubsection{Variable Radius}
A circle on a two-dimensional plane can be described by following formula: \[ (x - a)^2 + (y - b)^2 = r^2  \]
, meaning the circle can be represented by the parameters (a, b, r), where "a" and "b" are the 2-Dimensional coordinate values representing the center of the circle, whereas the variable "r" provides the radius of given ring. \newline
The preprocessing (Figure: \ref{fig:binary_image} and Figure: \ref{fig:edge_detected_image}) is identical to the fixed-radius Circle Hough Transform, but what makes the difference now is, our Accumulation Matrix gains another Dimension, from having variable radii, therefore it is 3-Dimensional now. Usually you specify a range for the radiuses to make things a little easier. Now the voting happens exactly as it would with algorithm described before, but the difference now is that it has to be done with every radius in the before determined range. The center of the potential circles are now the ones with the most voted radii in all radius-dimensions. The desired radius of a point is the radius with the highest vote.

\section{Classification}
Preceding stage delivers an image of fixed size, that needs to be categorized into one out of 10 groups, these are Speed limits "10km/h", "20km/h",..., "90km/h" and "no sign". To gain these information about the sub-image of the original image, I decided to apply a Feed Forward Deep Neural Network. Said Neural Network is fed each individual pixel, provided by the ROI to its input neurons, the trained Model then outputs a prediction on what class the input picture might belong to. 
\newline
wieso nur bis 90? 
\newline
Neuronales netz model